{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cfa4675",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimblearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, models\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f867f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('missiles-acled-18-october-2023.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d1f31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter relevant missile attack events\n",
    "data = data[(data['sub_event_type'].isin(['Shelling/artillery/missile attack', 'Air/drone strike'])) &\n",
    "            (data['actor1'] == 'Military Forces of Israel (2022-)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaf1d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "data['latitude'] = data['latitude'].fillna(data['latitude'].mean())\n",
    "data['longitude'] = data['longitude'].fillna(data['longitude'].mean())\n",
    "data['fatalities'] = data['fatalities'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ddc8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate data by location\n",
    "agg_data = data.groupby('location').agg({\n",
    "    'event_id_cnty': 'count',\n",
    "    'fatalities': 'sum',\n",
    "    'latitude': 'mean',\n",
    "    'longitude': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "agg_data.rename(columns={'event_id_cnty': 'missile_attack_count', 'fatalities': 'total_fatalities'}, inplace=True)\n",
    "\n",
    "# PTSD Likelihood Proxy Label\n",
    "agg_data['ptsd_likelihood'] = agg_data.apply(\n",
    "    lambda row: 1 if row['missile_attack_count'] > 3 and row['total_fatalities'] > 1 else 0, axis=1\n",
    ")\n",
    "\n",
    "# Feature Engineering\n",
    "agg_data['attack_fatality_interaction'] = agg_data['missile_attack_count'] * agg_data['total_fatalities']\n",
    "agg_data['log_missile_attack_count'] = np.log1p(agg_data['missile_attack_count'])\n",
    "agg_data['log_total_fatalities'] = np.log1p(agg_data['total_fatalities'])\n",
    "\n",
    "features = ['missile_attack_count', 'total_fatalities',\n",
    "            'attack_fatality_interaction', 'log_missile_attack_count', 'log_total_fatalities']\n",
    "X = agg_data[features]\n",
    "y = agg_data['ptsd_likelihood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab9a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab22d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec50834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE to balance the data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9eb6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer model for tabular data\n",
    "input_layer = layers.Input(shape=(X_train_smote.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54192cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project features into a dense space (simulate embedding)\n",
    "x = layers.Dense(128, activation='relu')(input_layer)\n",
    "x = tf.expand_dims(x, axis=1)  # Make input 3D for attention\n",
    "\n",
    "# Transformer block\n",
    "attention_output = layers.MultiHeadAttention(num_heads=4, key_dim=128)(x, x)\n",
    "attention_output = layers.GlobalAveragePooling1D()(attention_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedforward network\n",
    "x = layers.Dense(128, activation='relu')(attention_output)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "output = layers.Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857b5d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model = models.Model(inputs=input_layer, outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0502a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n",
    "model.fit(X_train_smote, y_train_smote, epochs=10, batch_size=16, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d2256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
